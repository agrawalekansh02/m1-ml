{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# demo train with `wandb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os, wandb, time, random\n",
    "from wandb.keras import WandbCallback\n",
    "from resnet34 import ResNet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import keras\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "num_classes = 10\n",
    "input_shape = X_train[0].shape\n",
    "print(input_shape)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "Y_train = keras.utils.np_utils.to_categorical(Y_train, num_classes)\n",
    "Y_test = keras.utils.np_utils.to_categorical(Y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mh3x4g0n\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "/home/hexagon/miniconda3/envs/tf37/lib/python3.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated since IPython 4.0. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.18 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hexagon/Code/m1-ml/models/wandb/run-20220616_233645-y285mkde</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/h3x4g0n/cifar-10-grid/runs/y285mkde\" target=\"_blank\">vital-rain-6</a></strong> to <a href=\"https://wandb.ai/h3x4g0n/cifar-10-grid\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# wandb run config\n",
    "wandb.login()\n",
    "config = dict(epochs=25,\n",
    "              batch_size=128,\n",
    "              latent=1024,\n",
    "              loss_fn='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              architecture='resnet34',\n",
    "              activation='softmax')\n",
    "run = wandb.init(project=\"cifar-10-grid\", \n",
    "                config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-16 23:36:51.251013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 23:36:51.278132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 23:36:51.278288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 23:36:51.278667: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-16 23:36:51.279460: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 23:36:51.279578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 23:36:51.279680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 23:36:51.735319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 23:36:51.735933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 23:36:51.736043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-06-16 23:36:51.736137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6048 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:09:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 16, 16, 64)        9472      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16, 16, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 8, 8, 64)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " residual_block (ResidualBlo  (None, 8, 8, 64)         74368     \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " residual_block_1 (ResidualB  (None, 8, 8, 64)         74368     \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_2 (ResidualB  (None, 8, 8, 64)         74368     \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_3 (ResidualB  (None, 4, 4, 128)        231296    \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_4 (ResidualB  (None, 4, 4, 128)        296192    \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_5 (ResidualB  (None, 4, 4, 128)        296192    \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_6 (ResidualB  (None, 4, 4, 128)        296192    \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_7 (ResidualB  (None, 2, 2, 256)        921344    \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_8 (ResidualB  (None, 2, 2, 256)        1182208   \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_9 (ResidualB  (None, 2, 2, 256)        1182208   \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_10 (Residual  (None, 2, 2, 256)        1182208   \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " residual_block_11 (Residual  (None, 2, 2, 256)        1182208   \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " residual_block_12 (Residual  (None, 2, 2, 256)        1182208   \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " residual_block_13 (Residual  (None, 1, 1, 512)        3677696   \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " residual_block_14 (Residual  (None, 1, 1, 512)        4723712   \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " residual_block_15 (Residual  (None, 1, 1, 512)        4723712   \n",
      " Block)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              525312    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,845,770\n",
      "Trainable params: 21,828,746\n",
      "Non-trainable params: 17,024\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model init\n",
    "model = ResNet34(latent=1024, n_classes=num_classes, activation=config[\"activation\"])\n",
    "model.build(input_shape=(1, *X_train[0].shape))\n",
    "print(model.summary(X_train[0].shape))\n",
    "model.compile(optimizer=config[\"optimizer\"], loss=config[\"loss_fn\"], metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-16 23:36:55.823570: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8400\n",
      "2022-06-16 23:36:56.743380: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - ETA: 0s - loss: 1.6330 - accuracy: 0.4440"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model in the h5py format. The model will be saved as W&B Artifacts in the SavedModel format.\n",
      "2022-06-16 23:37:09.954279: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as conv_169_layer_call_fn, conv_169_layer_call_and_return_conditional_losses, activation_1_layer_call_fn, activation_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn while saving (showing 5 of 134). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hexagon/Code/m1-ml/models/wandb/run-20220616_233645-y285mkde/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hexagon/Code/m1-ml/models/wandb/run-20220616_233645-y285mkde/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/hexagon/Code/m1-ml/models/wandb/run-20220616_233645-y285mkde/files/model-best)... Done. 0.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 22s 47ms/step - loss: 1.6330 - accuracy: 0.4440 - val_loss: 4.9312 - val_accuracy: 0.4471 - _timestamp: 1655447827.0000 - _runtime: 22.0000\n",
      "Epoch 2/25\n",
      "389/391 [============================>.] - ETA: 0s - loss: 1.1439 - accuracy: 0.5928"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv_169_layer_call_fn, conv_169_layer_call_and_return_conditional_losses, activation_1_layer_call_fn, activation_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn while saving (showing 5 of 134). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hexagon/Code/m1-ml/models/wandb/run-20220616_233645-y285mkde/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hexagon/Code/m1-ml/models/wandb/run-20220616_233645-y285mkde/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/hexagon/Code/m1-ml/models/wandb/run-20220616_233645-y285mkde/files/model-best)... Done. 0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 17s 43ms/step - loss: 1.1435 - accuracy: 0.5931 - val_loss: 1.1930 - val_accuracy: 0.5773 - _timestamp: 1655447844.0000 - _runtime: 39.0000\n",
      "Epoch 3/25\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.9565 - accuracy: 0.6608 - val_loss: 1.1938 - val_accuracy: 0.5892 - _timestamp: 1655447861.0000 - _runtime: 56.0000\n",
      "Epoch 4/25\n",
      "391/391 [==============================] - ETA: 0s - loss: 0.8025 - accuracy: 0.7186"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv_169_layer_call_fn, conv_169_layer_call_and_return_conditional_losses, activation_1_layer_call_fn, activation_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn while saving (showing 5 of 134). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hexagon/Code/m1-ml/models/wandb/run-20220616_233645-y285mkde/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hexagon/Code/m1-ml/models/wandb/run-20220616_233645-y285mkde/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/hexagon/Code/m1-ml/models/wandb/run-20220616_233645-y285mkde/files/model-best)... Done. 0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 17s 43ms/step - loss: 0.8025 - accuracy: 0.7186 - val_loss: 1.0738 - val_accuracy: 0.6240 - _timestamp: 1655447869.0000 - _runtime: 64.0000\n",
      "Epoch 5/25\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.7022 - accuracy: 0.7553 - val_loss: 1.3105 - val_accuracy: 0.5879 - _timestamp: 1655447886.0000 - _runtime: 81.0000\n",
      "Epoch 6/25\n",
      "390/391 [============================>.] - ETA: 0s - loss: 0.6045 - accuracy: 0.7876"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv_169_layer_call_fn, conv_169_layer_call_and_return_conditional_losses, activation_1_layer_call_fn, activation_1_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn while saving (showing 5 of 134). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hexagon/Code/m1-ml/models/wandb/run-20220616_233645-y285mkde/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/hexagon/Code/m1-ml/models/wandb/run-20220616_233645-y285mkde/files/model-best/assets\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/hexagon/Code/m1-ml/models/wandb/run-20220616_233645-y285mkde/files/model-best)... Done. 0.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 17s 44ms/step - loss: 0.6047 - accuracy: 0.7877 - val_loss: 0.9136 - val_accuracy: 0.6912 - _timestamp: 1655447895.0000 - _runtime: 90.0000\n",
      "Epoch 7/25\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.5346 - accuracy: 0.8135 - val_loss: 1.0274 - val_accuracy: 0.6657 - _timestamp: 1655447913.0000 - _runtime: 108.0000\n",
      "Epoch 8/25\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.4592 - accuracy: 0.8396 - val_loss: 0.9228 - val_accuracy: 0.7032 - _timestamp: 1655447922.0000 - _runtime: 117.0000\n",
      "Epoch 9/25\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 0.4222 - accuracy: 0.8539 - val_loss: 1.2284 - val_accuracy: 0.6353 - _timestamp: 1655447930.0000 - _runtime: 125.0000\n",
      "Epoch 10/25\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.3394 - accuracy: 0.8819 - val_loss: 0.9430 - val_accuracy: 0.7223 - _timestamp: 1655447939.0000 - _runtime: 134.0000\n",
      "Epoch 11/25\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.2932 - accuracy: 0.8964 - val_loss: 1.0880 - val_accuracy: 0.7033 - _timestamp: 1655447948.0000 - _runtime: 143.0000\n",
      "Epoch 12/25\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.2450 - accuracy: 0.9157 - val_loss: 1.4497 - val_accuracy: 0.6411 - _timestamp: 1655447957.0000 - _runtime: 152.0000\n",
      "Epoch 13/25\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.2002 - accuracy: 0.9302 - val_loss: 1.1908 - val_accuracy: 0.6932 - _timestamp: 1655447966.0000 - _runtime: 161.0000\n",
      "Epoch 14/25\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.1733 - accuracy: 0.9390 - val_loss: 1.2936 - val_accuracy: 0.7038 - _timestamp: 1655447975.0000 - _runtime: 170.0000\n",
      "Epoch 15/25\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.1546 - accuracy: 0.9461 - val_loss: 1.1181 - val_accuracy: 0.7215 - _timestamp: 1655447984.0000 - _runtime: 179.0000\n",
      "Epoch 16/25\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.1347 - accuracy: 0.9533 - val_loss: 1.1232 - val_accuracy: 0.7315 - _timestamp: 1655447993.0000 - _runtime: 188.0000\n",
      "Epoch 17/25\n",
      "391/391 [==============================] - 9s 22ms/step - loss: 0.1213 - accuracy: 0.9569 - val_loss: 1.2708 - val_accuracy: 0.7154 - _timestamp: 1655448002.0000 - _runtime: 197.0000\n",
      "Epoch 18/25\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.1111 - accuracy: 0.9621 - val_loss: 1.5799 - val_accuracy: 0.6599 - _timestamp: 1655448010.0000 - _runtime: 205.0000\n",
      "Epoch 19/25\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.1079 - accuracy: 0.9628 - val_loss: 1.4901 - val_accuracy: 0.6788 - _timestamp: 1655448019.0000 - _runtime: 214.0000\n",
      "Epoch 20/25\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.0985 - accuracy: 0.9655 - val_loss: 1.3815 - val_accuracy: 0.7132 - _timestamp: 1655448028.0000 - _runtime: 223.0000\n",
      "Epoch 21/25\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.1078 - accuracy: 0.9632 - val_loss: 1.2159 - val_accuracy: 0.7256 - _timestamp: 1655448038.0000 - _runtime: 233.0000\n",
      "Epoch 22/25\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.0880 - accuracy: 0.9693 - val_loss: 1.4098 - val_accuracy: 0.7186 - _timestamp: 1655448047.0000 - _runtime: 242.0000\n",
      "Epoch 23/25\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.0791 - accuracy: 0.9732 - val_loss: 1.3845 - val_accuracy: 0.7156 - _timestamp: 1655448055.0000 - _runtime: 250.0000\n",
      "Epoch 24/25\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.0839 - accuracy: 0.9703 - val_loss: 1.5932 - val_accuracy: 0.6742 - _timestamp: 1655448064.0000 - _runtime: 259.0000\n",
      "Epoch 25/25\n",
      "391/391 [==============================] - 9s 23ms/step - loss: 0.0712 - accuracy: 0.9753 - val_loss: 1.3096 - val_accuracy: 0.7314 - _timestamp: 1655448073.0000 - _runtime: 268.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▇████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▄▅▄▇▆▇▆█▇▆▇▇███▆▇████▇█</td></tr><tr><td>val_loss</td><td>█▁▁▁▂▁▁▁▂▁▁▂▁▂▁▁▂▂▂▂▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.97532</td></tr><tr><td>best_epoch</td><td>5</td></tr><tr><td>best_val_loss</td><td>0.91357</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.07124</td></tr><tr><td>val_accuracy</td><td>0.7314</td></tr><tr><td>val_loss</td><td>1.30963</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">vital-rain-6</strong>: <a href=\"https://wandb.ai/h3x4g0n/cifar-10-grid/runs/y285mkde\" target=\"_blank\">https://wandb.ai/h3x4g0n/cifar-10-grid/runs/y285mkde</a><br/>Synced 6 W&B file(s), 1 media file(s), 13 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220616_233645-y285mkde/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# model train with WandbCallback\n",
    "val_images, val_labels = X_test[:32], Y_test[:32]\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "            epochs=config[\"epochs\"], \n",
    "            batch_size=config[\"batch_size\"],\n",
    "            validation_data=(X_test, Y_test),\n",
    "            callbacks=[WandbCallback()])\n",
    "\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tf37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b5e598761a2ac5bb93299115b047ed6d25e008cb3e4097da7606351e4132c77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
