{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# unet training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hexagon/miniconda3/envs/torch39/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from unet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# cifar10\n",
    "batch_size = 64\n",
    "num_train = 10000\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "     \n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainset = torch.utils.data.Subset(trainset, range(num_train))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 960, 540]           1,728\n",
      "       BatchNorm2d-2         [-1, 64, 960, 540]             128\n",
      "              ReLU-3         [-1, 64, 960, 540]               0\n",
      "            Conv2d-4         [-1, 64, 960, 540]          36,864\n",
      "       BatchNorm2d-5         [-1, 64, 960, 540]             128\n",
      "              ReLU-6         [-1, 64, 960, 540]               0\n",
      "      DoubleConv2d-7         [-1, 64, 960, 540]               0\n",
      "         MaxPool2d-8         [-1, 64, 480, 270]               0\n",
      "            Conv2d-9        [-1, 128, 480, 270]          73,728\n",
      "      BatchNorm2d-10        [-1, 128, 480, 270]             256\n",
      "             ReLU-11        [-1, 128, 480, 270]               0\n",
      "           Conv2d-12        [-1, 128, 480, 270]         147,456\n",
      "      BatchNorm2d-13        [-1, 128, 480, 270]             256\n",
      "             ReLU-14        [-1, 128, 480, 270]               0\n",
      "     DoubleConv2d-15        [-1, 128, 480, 270]               0\n",
      "             Down-16        [-1, 128, 480, 270]               0\n",
      "        MaxPool2d-17        [-1, 128, 240, 135]               0\n",
      "           Conv2d-18        [-1, 256, 240, 135]         294,912\n",
      "      BatchNorm2d-19        [-1, 256, 240, 135]             512\n",
      "             ReLU-20        [-1, 256, 240, 135]               0\n",
      "           Conv2d-21        [-1, 256, 240, 135]         589,824\n",
      "      BatchNorm2d-22        [-1, 256, 240, 135]             512\n",
      "             ReLU-23        [-1, 256, 240, 135]               0\n",
      "     DoubleConv2d-24        [-1, 256, 240, 135]               0\n",
      "             Down-25        [-1, 256, 240, 135]               0\n",
      "        MaxPool2d-26         [-1, 256, 120, 67]               0\n",
      "           Conv2d-27         [-1, 512, 120, 67]       1,179,648\n",
      "      BatchNorm2d-28         [-1, 512, 120, 67]           1,024\n",
      "             ReLU-29         [-1, 512, 120, 67]               0\n",
      "           Conv2d-30         [-1, 512, 120, 67]       2,359,296\n",
      "      BatchNorm2d-31         [-1, 512, 120, 67]           1,024\n",
      "             ReLU-32         [-1, 512, 120, 67]               0\n",
      "     DoubleConv2d-33         [-1, 512, 120, 67]               0\n",
      "             Down-34         [-1, 512, 120, 67]               0\n",
      "        MaxPool2d-35          [-1, 512, 60, 33]               0\n",
      "           Conv2d-36          [-1, 512, 60, 33]       2,359,296\n",
      "      BatchNorm2d-37          [-1, 512, 60, 33]           1,024\n",
      "             ReLU-38          [-1, 512, 60, 33]               0\n",
      "           Conv2d-39          [-1, 512, 60, 33]       2,359,296\n",
      "      BatchNorm2d-40          [-1, 512, 60, 33]           1,024\n",
      "             ReLU-41          [-1, 512, 60, 33]               0\n",
      "     DoubleConv2d-42          [-1, 512, 60, 33]               0\n",
      "             Down-43          [-1, 512, 60, 33]               0\n",
      "         Upsample-44            [-1, 512, 2, 2]               0\n",
      "           Conv2d-45         [-1, 512, 120, 67]       4,718,592\n",
      "      BatchNorm2d-46         [-1, 512, 120, 67]           1,024\n",
      "             ReLU-47         [-1, 512, 120, 67]               0\n",
      "           Conv2d-48         [-1, 256, 120, 67]       1,179,648\n",
      "      BatchNorm2d-49         [-1, 256, 120, 67]             512\n",
      "             ReLU-50         [-1, 256, 120, 67]               0\n",
      "     DoubleConv2d-51         [-1, 256, 120, 67]               0\n",
      "               Up-52         [-1, 256, 120, 67]               0\n",
      "         Upsample-53            [-1, 256, 2, 2]               0\n",
      "           Conv2d-54        [-1, 256, 240, 135]       1,179,648\n",
      "      BatchNorm2d-55        [-1, 256, 240, 135]             512\n",
      "             ReLU-56        [-1, 256, 240, 135]               0\n",
      "           Conv2d-57        [-1, 128, 240, 135]         294,912\n",
      "      BatchNorm2d-58        [-1, 128, 240, 135]             256\n",
      "             ReLU-59        [-1, 128, 240, 135]               0\n",
      "     DoubleConv2d-60        [-1, 128, 240, 135]               0\n",
      "               Up-61        [-1, 128, 240, 135]               0\n",
      "         Upsample-62            [-1, 128, 2, 2]               0\n",
      "           Conv2d-63        [-1, 128, 480, 270]         294,912\n",
      "      BatchNorm2d-64        [-1, 128, 480, 270]             256\n",
      "             ReLU-65        [-1, 128, 480, 270]               0\n",
      "           Conv2d-66         [-1, 64, 480, 270]          73,728\n",
      "      BatchNorm2d-67         [-1, 64, 480, 270]             128\n",
      "             ReLU-68         [-1, 64, 480, 270]               0\n",
      "     DoubleConv2d-69         [-1, 64, 480, 270]               0\n",
      "               Up-70         [-1, 64, 480, 270]               0\n",
      "         Upsample-71             [-1, 64, 2, 2]               0\n",
      "           Conv2d-72         [-1, 64, 960, 540]          73,728\n",
      "      BatchNorm2d-73         [-1, 64, 960, 540]             128\n",
      "             ReLU-74         [-1, 64, 960, 540]               0\n",
      "           Conv2d-75         [-1, 64, 960, 540]          36,864\n",
      "      BatchNorm2d-76         [-1, 64, 960, 540]             128\n",
      "             ReLU-77         [-1, 64, 960, 540]               0\n",
      "     DoubleConv2d-78         [-1, 64, 960, 540]               0\n",
      "               Up-79         [-1, 64, 960, 540]               0\n",
      "           Conv2d-80          [-1, 2, 960, 540]             130\n",
      "          Sigmoid-81          [-1, 2, 960, 540]               0\n",
      "================================================================\n",
      "Total params: 17,263,042\n",
      "Trainable params: 17,263,042\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 5.93\n",
      "Forward/backward pass size (MB): 6979.83\n",
      "Params size (MB): 65.85\n",
      "Estimated Total Size (MB): 7051.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# config\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = UNet(in_channels=3, out_channels=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "summary(model, (3, 1920//2, 1080//2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/157 [00:00<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "only batches of spatial targets supported (3D tensors) but got targets of size: : [64]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/hexagon/Code/m1-ml/models/torch/unet_train.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml/home/hexagon/Code/m1-ml/models/torch/unet_train.ipynb#ch0000004vscode-remote?line=13'>14</a>\u001b[0m \u001b[39m# forward + backward + optimize\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml/home/hexagon/Code/m1-ml/models/torch/unet_train.ipynb#ch0000004vscode-remote?line=14'>15</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(data)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bml/home/hexagon/Code/m1-ml/models/torch/unet_train.ipynb#ch0000004vscode-remote?line=15'>16</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(outputs, target)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml/home/hexagon/Code/m1-ml/models/torch/unet_train.ipynb#ch0000004vscode-remote?line=16'>17</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bml/home/hexagon/Code/m1-ml/models/torch/unet_train.ipynb#ch0000004vscode-remote?line=17'>18</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch39/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch39/lib/python3.9/site-packages/torch/nn/modules/loss.py:1163\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m-> 1163\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[1;32m   1164\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[1;32m   1165\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch39/lib/python3.9/site-packages/torch/nn/functional.py:2996\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   2994\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2995\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 2996\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: only batches of spatial targets supported (3D tensors) but got targets of size: : [64]"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(20): \n",
    "    with tqdm(trainloader, unit=\"batch\") as tepoch:\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for data, target in tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch}\")\n",
    "            \n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(data).to(device)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # calculating accuracy\n",
    "            predictions = outputs.argmax(dim=1, keepdim=True)\n",
    "            correct = (predictions == target).sum().item()\n",
    "            accuracy = correct / batch_size\n",
    "\n",
    "            # print statistics\n",
    "            tepoch.set_postfix(loss=loss.item(), accuracy=100.*accuracy)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "# PATH = './cifar_net.pth'\n",
    "# torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "# print images\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(torchvision.utils.make_grid(images.cpu()).permute(1, 2, 0))\n",
    "print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('torch39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6c173af3f897aae50989b88c2c053f9be2d0ba349e623fe7991100b9b0a25dca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
